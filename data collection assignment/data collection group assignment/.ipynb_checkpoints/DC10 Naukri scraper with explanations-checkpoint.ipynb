{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names: Sandipto Sanyal\n",
    "# PGIDs: 12010004\n",
    "# Project description\n",
    "Below is our project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "Used Chrome driver for version Chrome version 83.<br>\n",
    "For other chrome versions Download the related driver from: https://chromedriver.chromium.org/downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages required\n",
    "Uncomment and run if not selenium installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.common import exceptions\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User configurable variables\n",
    "search_criteria and pages_to_scan are user configurable. They denote the course names and number of pages to scan for each course name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_criteria = ['data science','photography', 'music', 'aws']\n",
    "pages_to_scan=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch the chrome browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument(\"--test-type\")\n",
    "locationOfWebdriver = \"./chromedriver_win32/chromedriver.exe\"\n",
    "\n",
    "driver = webdriver.Chrome(locationOfWebdriver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visit Udemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.udemy.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for courses through the search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_the_course(search_criteria: str):\n",
    "    '''\n",
    "    Run the website actions like scrolling to load the price tags\n",
    "    '''\n",
    "    def find_the_course_search_box():\n",
    "        '''\n",
    "        Target the search box using native Javascript and interact with it.\n",
    "        Highlevel selenium API was not able to interact with the searchbox\n",
    "        '''\n",
    "        course_search_box = driver.find_element_by_xpath('//input[@placeholder=\"Search for anything\" \\\n",
    "                                                          ]')\n",
    "        # selenium highlevel API was not able to interact with the search box\n",
    "        # so went into javascript level to\n",
    "        driver.execute_script(\"arguments[0].value='{}';\".format(search_criteria), \n",
    "                              course_search_box\n",
    "                             )\n",
    "        course_search_box.submit()\n",
    "        \n",
    "    # Now do a new search for the course in search bar\n",
    "    course_to_search = search_criteria\n",
    "    find_the_course_search_box()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scroll the page\n",
    "Udemy does a lazy loading of course headers. Thus we scroll the page before parsing the XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_the_page():\n",
    "    # scroll to the bottom of the page to load the price tags else they are kept hidden.\n",
    "    # This is dynamically generated on scrolling to the bottom\n",
    "    scroll_step = 250\n",
    "    max_scroll_limit = 5500\n",
    "    for scroll in range(500,max_scroll_limit, scroll_step):\n",
    "        driver.execute_script(\"window.scrollTo(0, {})\".format(scroll))\n",
    "        # at last scroll to the bottom of the page\n",
    "        if scroll + scroll_step >= max_scroll_limit:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # give 1s of time to load the prices\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go to the next page\n",
    "Below we define a method to go to the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_next_page():\n",
    "    print('going to next page...')\n",
    "    next_button = driver.find_element_by_xpath('//a[@data-page=\"+1\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the current URL after hitting the location search\n",
    "Below we see the current URL our driver arrived to be sure we are searching in the right section of our page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current URL we arrived:https://www.udemy.com/\n"
     ]
    }
   ],
   "source": [
    "print('Current URL we arrived:{}'.format(driver.current_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the XML\n",
    "Here we take help of BeautifulSoup to inspect the elements.\n",
    "1. First take all the list of jobs in each page\n",
    "2. For each list travel inside the XML tree to search for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop with all the search criteria and the individual individual whole page to extract course related information\n",
    "Go to the automated chrome browser to view how selenium is putting the search criteria one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Search criteria:data science\n",
      "URL scraping: https://www.udemy.com/courses/search/?q=data+science\n",
      "Number of courses found on page 1: 26\n",
      "going to next page...\n",
      "URL scraping: https://www.udemy.com/courses/search/?p=2&q=data+science\n",
      "Number of courses found on page 2: 28\n",
      "going to next page...\n",
      "\n",
      "----------------------------------------\n",
      "Search criteria:photography\n",
      "URL scraping: https://www.udemy.com/courses/photography/?search-query=photography\n",
      "Number of courses found on page 1: 19\n",
      "going to next page...\n",
      "URL scraping: https://www.udemy.com/courses/photography/?p=2&search-query=photography\n",
      "Number of courses found on page 2: 20\n",
      "going to next page...\n",
      "\n",
      "----------------------------------------\n",
      "Search criteria:music\n",
      "URL scraping: https://www.udemy.com/courses/music/?search-query=music\n",
      "Number of courses found on page 1: 20\n",
      "going to next page...\n",
      "URL scraping: https://www.udemy.com/courses/music/?p=2&search-query=music\n",
      "Number of courses found on page 2: 20\n",
      "going to next page...\n",
      "\n",
      "----------------------------------------\n",
      "Search criteria:aws\n"
     ]
    }
   ],
   "source": [
    "data = {'search_criteria':[],\n",
    "        'course_name':[],\n",
    "        'course_description':[],\n",
    "        'rating':[],\n",
    "        'no_of_reviews':[],\n",
    "        'duration':[],\n",
    "        'lectures':[],\n",
    "        'levels':[],\n",
    "        'badge': [],\n",
    "        'original_price':[],\n",
    "        'discounted_price':[],\n",
    "       }\n",
    "for search in search_criteria:\n",
    "    print('\\n----------------------------------------\\nSearch criteria:{}'.format(search))\n",
    "    # run the website scrolling actions\n",
    "    search_the_course(search)\n",
    "    for page in range(1,pages_to_scan+1):\n",
    "        # scroll the page to load the prices\n",
    "        scroll_the_page()\n",
    "        print('URL scraping: {}'.format(driver.current_url))\n",
    "        # get the page xml\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        # list the courses\n",
    "        courses = soup.find_all('div',class_='course-card--main-content--3xEIw course-card--has-price-text--1Ikr0')\n",
    "        print('Number of courses found on page {}: {}'.format(page, len(courses)))\n",
    "        for course in courses:\n",
    "            try: \n",
    "                data['search_criteria'].append(search)\n",
    "            except: \n",
    "                data['search_criteria'].append(None)\n",
    "            try:\n",
    "                data['course_name'].append(course.div.get_text()); \n",
    "            except: \n",
    "                data['course_name'].append(None)\n",
    "            try: \n",
    "                data['course_description'].append(course.p.get_text()); \n",
    "            except: data['course_description'].append(None)\n",
    "            try: \n",
    "                data['rating'].append(float(course.find('div',class_='course-card--star-rating-wrapper--wwCqc').span.find_all('span')[1].get_text())); \n",
    "            except: \n",
    "                data['rating'].append(None)\n",
    "            try: \n",
    "                data['no_of_reviews'].append(course.find('div',class_='course-card--star-rating-wrapper--wwCqc').find_all('span')[4].get_text()); \n",
    "            except: \n",
    "                data['no_of_reviews'].append(None)\n",
    "            try: \n",
    "                data['duration'].append(course.find_all('div')[3].find_all('span')[0].get_text());\n",
    "            except: \n",
    "                data['duration'].append(None)\n",
    "            try: \n",
    "                data['lectures'].append(course.find_all('div')[3].find_all('span')[1].get_text()); \n",
    "            except: \n",
    "                data['lectures'].append(None)\n",
    "            try:\n",
    "                data['levels'].append(course.find_all('div')[3].find_all('span')[2].get_text()); \n",
    "            except: \n",
    "                data['levels'].append(None)\n",
    "            try: \n",
    "                data['badge'].append(None) # couldn't extract this one will see later\n",
    "            except:\n",
    "                data['badge'].append(None)\n",
    "            try:\n",
    "                data['discounted_price'].append(float(re.sub('\\u20B9|\\,','',course.find('div',attrs={'data-purpose':\"price-text-container\"}).find_all('div')[0].find_all('span')[1].span.get_text()))); \n",
    "            except: data['discounted_price'].append(None)\n",
    "            try: \n",
    "                data['original_price'].append(float(re.sub('\\u20B9|\\,','',course.find('div',attrs={'data-purpose':\"original-price-container\"}).find_all('div')[0].find_all('span')[1].span.get_text()))); \n",
    "            except: \n",
    "                data['original_price'].append(None)\n",
    "        try:\n",
    "            # visit next page\n",
    "            go_to_next_page()\n",
    "        except exceptions.ElementClickInterceptedException:\n",
    "            try:\n",
    "               go_to_next_page()\n",
    "            except exceptions.ElementClickInterceptedException:\n",
    "                try:\n",
    "                    go_to_next_page()\n",
    "                except Exception as e:\n",
    "                    warnings.warn(\"Warning........... Couldn\\'t navigate to next page\")\n",
    "                    pass\n",
    "print('Search process ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_criteria</th>\n",
       "      <th>course_name</th>\n",
       "      <th>course_description</th>\n",
       "      <th>rating</th>\n",
       "      <th>no_of_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>lectures</th>\n",
       "      <th>levels</th>\n",
       "      <th>badge</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discounted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data science</td>\n",
       "      <td>The Data Science Course 2020: Complete Data Sc...</td>\n",
       "      <td>Complete Data Science Training: Mathematics, S...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(69,990)</td>\n",
       "      <td>29 total hours</td>\n",
       "      <td>471 lectures</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>None</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data science</td>\n",
       "      <td>Machine Learning A-Z™: Hands-On Python &amp; R In ...</td>\n",
       "      <td>Learn to create Machine Learning Algorithms in...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(126,640)</td>\n",
       "      <td>44.5 total hours</td>\n",
       "      <td>323 lectures</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>None</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data Science A-Z™: Real-Life Data Science Exer...</td>\n",
       "      <td>Learn Data Science step by step through real A...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(26,901)</td>\n",
       "      <td>21.5 total hours</td>\n",
       "      <td>217 lectures</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>None</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data Science: Supervised Machine Learning in P...</td>\n",
       "      <td>None</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(1,854)</td>\n",
       "      <td>Current price</td>\n",
       "      <td>₹7,680</td>\n",
       "      <td>₹7,680</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data science</td>\n",
       "      <td>Unsupervised Deep Learning in Python</td>\n",
       "      <td>None</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(1,452)</td>\n",
       "      <td>Current price</td>\n",
       "      <td>₹7,680</td>\n",
       "      <td>₹7,680</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>aws</td>\n",
       "      <td>Ultimate AWS Certified Solutions Architect Pro...</td>\n",
       "      <td>Be AWS Certified Solutions Architect Professio...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>(1,551)</td>\n",
       "      <td>13 total hours</td>\n",
       "      <td>132 lectures</td>\n",
       "      <td>Expert</td>\n",
       "      <td>None</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>aws</td>\n",
       "      <td>AWS DynamoDB - The Complete Guide (Build 18+ H...</td>\n",
       "      <td>Master Amazon DynamoDB, the Serverless NoSQL A...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>(1,005)</td>\n",
       "      <td>16.5 total hours</td>\n",
       "      <td>121 lectures</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>None</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>aws</td>\n",
       "      <td>AWS Certified Machine Learning Specialty 2020 ...</td>\n",
       "      <td>Learn SageMaker, feature engineering, model tu...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(1,689)</td>\n",
       "      <td>9.5 total hours</td>\n",
       "      <td>114 lectures</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>None</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>aws</td>\n",
       "      <td>AWS Certified Cloud Practitioner Practice Exams</td>\n",
       "      <td>Be an AWS Certified Cloud Practitioner! AWS Ce...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(767)</td>\n",
       "      <td>260 questions</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>aws</td>\n",
       "      <td>Amazon EKS Starter: Docker on AWS EKS with Kub...</td>\n",
       "      <td>Deploy Docker Containers on Kubernetes on AWS ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(1,170)</td>\n",
       "      <td>5.5 total hours</td>\n",
       "      <td>53 lectures</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>None</td>\n",
       "      <td>8320.0</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    search_criteria                                        course_name  \\\n",
       "0      data science  The Data Science Course 2020: Complete Data Sc...   \n",
       "1      data science  Machine Learning A-Z™: Hands-On Python & R In ...   \n",
       "2      data science  Data Science A-Z™: Real-Life Data Science Exer...   \n",
       "3      data science  Data Science: Supervised Machine Learning in P...   \n",
       "4      data science               Unsupervised Deep Learning in Python   \n",
       "..              ...                                                ...   \n",
       "176             aws  Ultimate AWS Certified Solutions Architect Pro...   \n",
       "177             aws  AWS DynamoDB - The Complete Guide (Build 18+ H...   \n",
       "178             aws  AWS Certified Machine Learning Specialty 2020 ...   \n",
       "179             aws    AWS Certified Cloud Practitioner Practice Exams   \n",
       "180             aws  Amazon EKS Starter: Docker on AWS EKS with Kub...   \n",
       "\n",
       "                                    course_description  rating no_of_reviews  \\\n",
       "0    Complete Data Science Training: Mathematics, S...     4.5      (69,990)   \n",
       "1    Learn to create Machine Learning Algorithms in...     4.5     (126,640)   \n",
       "2    Learn Data Science step by step through real A...     4.6      (26,901)   \n",
       "3                                                 None     4.6       (1,854)   \n",
       "4                                                 None     4.5       (1,452)   \n",
       "..                                                 ...     ...           ...   \n",
       "176  Be AWS Certified Solutions Architect Professio...     4.7       (1,551)   \n",
       "177  Master Amazon DynamoDB, the Serverless NoSQL A...     4.3       (1,005)   \n",
       "178  Learn SageMaker, feature engineering, model tu...     4.5       (1,689)   \n",
       "179  Be an AWS Certified Cloud Practitioner! AWS Ce...     4.5         (767)   \n",
       "180  Deploy Docker Containers on Kubernetes on AWS ...     4.5       (1,170)   \n",
       "\n",
       "             duration      lectures        levels badge  original_price  \\\n",
       "0      29 total hours  471 lectures    All Levels  None         12800.0   \n",
       "1    44.5 total hours  323 lectures    All Levels  None         12800.0   \n",
       "2    21.5 total hours  217 lectures    All Levels  None         12800.0   \n",
       "3       Current price        ₹7,680        ₹7,680  None             NaN   \n",
       "4       Current price        ₹7,680        ₹7,680  None             NaN   \n",
       "..                ...           ...           ...   ...             ...   \n",
       "176    13 total hours  132 lectures        Expert  None          8000.0   \n",
       "177  16.5 total hours  121 lectures    All Levels  None          1920.0   \n",
       "178   9.5 total hours  114 lectures  Intermediate  None         12800.0   \n",
       "179     260 questions      Beginner          None  None          1600.0   \n",
       "180   5.5 total hours   53 lectures  Intermediate  None          8320.0   \n",
       "\n",
       "     discounted_price  \n",
       "0               455.0  \n",
       "1               455.0  \n",
       "2               455.0  \n",
       "3              7680.0  \n",
       "4              7680.0  \n",
       "..                ...  \n",
       "176             455.0  \n",
       "177             455.0  \n",
       "178             455.0  \n",
       "179             468.0  \n",
       "180             455.0  \n",
       "\n",
       "[181 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data\n",
    "Above we can see that due to multiple types of contents our dataframe contains columns which are sort of incosistent like <b>no_of_reviews, duration, lectures, levels</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(row):\n",
    "    no_of_reviews = None\n",
    "    duration = None\n",
    "    lectures = None\n",
    "    levels = None\n",
    "    # check whether the row.duration contains a pattern like '<integer or fraction> total hour(s)\n",
    "    if (bool(re.search('(?<=>)\\d+.\\d+|\\d+ total hours|(?<=>)\\d+.\\d+|\\d+ total hour', row.duration))):\n",
    "        duration = row.duration\n",
    "    # check whether row.lectures follow a pattern '<integer or fraction> lecture(s)'\n",
    "    if (bool(re.search('(?<=>)\\d+.\\d+|\\d+ lectures|(?<=>)\\d+.\\d+|\\d+  lecture', row.lectures))):\n",
    "        lectures = row.lectures\n",
    "    # check whether row.levels shouldn't contain \\u20B9<integer or fraction>\n",
    "    if not (bool(re.search('\\u20B9', str(row.levels)))):\n",
    "        levels = row.levels\n",
    "    # also change no_of_reviews to integer\n",
    "    if (bool(re.search('\\(\\d+\\,\\d+\\)|\\(\\d+\\)', row.no_of_reviews))):\n",
    "        # substitute () and , with null strings\n",
    "        no_of_reviews = int(re.sub('[\\(\\)\\,]','',row.no_of_reviews))\n",
    "    return pd.Series([no_of_reviews, duration, lectures, levels])\n",
    "\n",
    "df[['no_of_reviews','duration','lectures','levels']] = df.apply(data_cleaner, axis=1)\n",
    "df.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
